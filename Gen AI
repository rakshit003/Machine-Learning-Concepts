AI is a general purpose technology because it can be used for muliple tasks.
Just like electricity or internet

Gen AI is a collection of tools tp generates high quality text image and audio including llms and difusion models for 
image generation.

LLM is trained to predict the next best word using 100s billions or trillion of exampples text in the internet

import openai
import os
​
openai.api_key = os.getenv("OPENAI_API_KEY")
​
def llm_response(prompt):
    response = openai.ChatCompletion

prompt = ''' food looks delicious '''
response=llm_response(prompt)
print(response)

RAG:
RAG Retrieval Augmented Generation is an important technique 
that is enabling many LLMs to have context or to have information beyond what it may have learned on the open Internet

for eg if your company has multiple internal policy documents for employees
RAG can help find the information in those docs by first providing more context to your question to your question
and then answer it

Usecase: Chat with PDF
LLMs may have read a lot of texts on the Internet, and so it's tempting to think of them as knowing a lot of things and they do,
but they don't know everything. 
With the rag approach, we provide relevant context in the prompt itself and we ask the LLM to read that piece of text and then to process it to get to the answer

Fine Tuning
This is another way to make the ouputs be more custom to your usecase
Genrelly Fine tuning is uesd when instructions are not easy to define in a prompt
for fine tuning will change the overall outcome to a specific style 

for eg: 
-if lets say you want to change the output style of text of gen AI to make it similar to how a person
talks. genreally you LLM might not be trained to have information of that person. So fine tuning the transcripts
of the person from past and changing the answer format to that sytle is a fine tuning example
-Also if we want to process some complicated documents like Doctor Transcripts, or legal transcripts which donot
user normal englisg and there are a lot of abbrevations used then its a good idea to fine tune it for that kind of wrinting
-Also if we have resorces of only small model(<1bill param). and we fine tune it on a specific task it can produce 
desired results


Which model to chose
- Small Models -- 1 bill params : basic world knowledge -- patter matching
- Medium Models - 10 bill params: Food Order chatbot. We don't need complex knowledge to build these apps
- LLM Models -- Rich world knowldge like phylosophy , art,physics ... brainstorming 

Instruction tuning:Generally task of LLM is to predict the next best word.But inorder to make LLM follow instructions
a technique is used to Help it guide the right answer. set of question and answers are used to fine tune.

RLHF is a technique used after fine tuning or Instruction tuning where various answers generated by LLM are scored
and that scored is passed as a reward to RL to help improve the answers


****Image Genration***

Gen AI use Difusion models which work on supervised learning to train image generation

Defusion model takes an image and keep on adding noise to that image step by step.
the model is then reverse trained to generate a less noise image from a 1 step back noisy image.

This process is then further complimented by a prompt text and in each noisyless image generation
both noisy image and the prompt is imputted to generate the less noisy image

With millions of images model learns to generate an image from 100% noise with the help of its supporting prompt

******LLM Applications******

--Writing: enter prompts to output big written texts
--Reading: Feed in data to clasify or summarise it
--Chatbot: Customer Agent Interation Augmentation

Also, we could have a Web Application or Software linked llm to perform the augmentation or automation
