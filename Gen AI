import openai
import os
​
openai.api_key = os.getenv("OPENAI_API_KEY")
​
def llm_response(prompt):
    response = openai.ChatCompletion

prompt = ''' food looks delicious '''
response=llm_response(prompt)
print(response)

RAG:
RAG Retrieval Augmented Generation is an important technique 
that is enabling many LLMs to have context or to have information beyond what it may have learned on the open Internet

for eg if your company has multiple internal policy documents for employees
RAG can help find the information in those docs by first providing more context to your question to your question
and then answer it

Usecase: Chat with PDF
LLMs may have read a lot of texts on the Internet, and so it's tempting to think of them as knowing a lot of things and they do,
but they don't know everything. 
With the rag approach, we provide relevant context in the prompt itself and we ask the LLM to read that piece of text and then to process it to get to the answer
