****Multi class classification in Nural net

Logistic Regression is a generalization of softmax regressign, for n=2
In order to achive multiclass in nuralnet we add a softmax function multi node only in the output layer 
a1= e^z1/e^z1+e^z2+.....e^zn   -- n is number of classes
all the other layer remain same as normal NN with 2 classes

Below is an example of how to construct this network in Tensorflow. 
Notice the output layer uses a linear rather than a softmax activation. 
While it is possible to include the softmax in the output layer, it is more numerically stable if 
linear outputs are passed to the loss function during training. 
If the model is used to predict probabilities, the softmax can be applied at that point.
**
tf.random.set_seed(1234)  # applied to achieve consistent results
model = Sequential(
    [
        Dense(2, activation = 'relu',   name = "L1"),
        Dense(4, activation = 'linear', name = "L2")
    ]
)

model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(0.01),
)

model.fit(
    X_train,y_train,
    epochs=200
)

*prediction

**
****Difference Between Loss and Cost Function
Loss function is defined for only 1 row(example) of the data set and a give point in time gives the loss of inputted row
Cost function is for all records. Its an average of loss of each record of the dataset, 
Gradient decent plots cost function against model weights and minimise the cost by adjusting the weights slowly

*****making multi class datatset for testing

# make 4-class dataset for classification
from sklearn.datasets import make_blobs
classes = 4
m = 100
centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]
std = 1.0
X_train, y_train = make_blobs(n_samples=m, centers=centers, cluster_std=std,random_state=30)
plt_mc(X_train,y_train,classes, centers, std=std)
# show classes in data set


print(f"unique classes {np.unique(y_train)}")
# show how classes are represented
print(f"class representation {y_train[:10]}")
# show shapes of our dataset
print(f"shape of X_train: {X_train.shape}, shape of y_train: {y_train.shape}")
